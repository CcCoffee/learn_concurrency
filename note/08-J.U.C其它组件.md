
## J.U.C中使用了AQS的同步组件
* CountDownLatch
* Semaphore
* CyclicBarrier
* ReentrantLock
* Condition
* FutureTask

# CountDownLatch

CountDownLatch是一个同步辅助类，通过它可以完成类似于阻塞当前线程的功能，换句话说就是一个线程或
多个线程一致等待直到其他线程执行的操作完成。CountDownLatch用了一个给定的计数器来进行初始化，
该计数器的操作是原子操作。就是同时只能有一个线程去操作该计数器。调用该类的await方法的线程会一直
处于阻塞状态，直到其他线程调用countDown方法使当前计数器的值减少到0。每次调用countDown的时候
计数器的值会减一，当计数器的值减到0的时候所有因为调用await方法而处于等待状态的线程就会继续往下
执行。这种操作只会出现一次，因为计数器是不能被重置的。如果业务上需要一个可以重置计数次数的版本可
以考虑使用`CyclicBarrier`

## 使用场景
程序执行需要等待某些条件完成后才能继续执行后续的操作，典型的应用比如说并行计算。当有一个运算量很大
的任务，我们可以将它拆分为多个子任务，等所有子任务全部完成之后，父任务再执行最后的汇总工作。

### 并发模拟
为什么并发模拟的时候可以使用CountDownLatch呢？因为我们模拟的场景是有5000个请求，每一个分别去执
行一个函数，实际的函数可以非常复杂和耗时，需要等待所有这些请求被处理完再统计结果，也就是实际请求
总数。通过CountDownLatch可以保证这些请求都被处理完才去输出最终的统计结果。过程中每一个请求都可以
看作是一个子任务。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gbdqbjsn4rj30l40jq43e.jpg" alt="image-20200129205914986" style="zoom:60%;" />

# Semaphore
Semaphore是AQS里的同步组件，叫做信号量。并发模拟的时候可以控制并发访问的线程数。操作系统中在进程
控制方面有很大的应用。java并发库里的Semaphore可以很轻松的完成类似于操作系统中信号量的控制。它可以
很容易的控制某个资源可被同时访问的个数。和CountDownLatch使用有些类似，也是提供了两个核心方法，分
别是acquire和release。acquire方法是获取一个许可，如果没有就等待。release是在操作完成后释放一个
许可。Semaphore维护了当前访问的个数，通过提供同步机制来控制同时访问的个数。在数据结构中的链表正常
是可以保存无限个节点的，而Semaphore可以实现有限大小的列表，这里重入锁也可以实现这个功能，但是实现
上要复杂很多。

## 使用场景
Semaphore常用于仅能提供有限访问的资源，比如数据库连接数最大只有20，而上层应用并发数可能会远远大于
20，如果同时对数据库进行操作就可能出现因为无法获取数据库连接而导致异常，这时候可以通过Semaphore来
做并发访问控制。当Semaphore把并发控制到1时就跟单线程很相似。

# CyclicBarrier

![image-20200130105618676](https://tva1.sinaimg.cn/large/006tNbRwgy1gbeeigzsijj30bm0ba40s.jpg)

CyclicBarrier是AQS里的同步辅助类，它允许一组线程相互等待，直到到达某个公共的屏障点
(Common Barrier point)，通过它可以完成多个线程之间相互等待，只有当每个线程都准备就绪之后
才能继续执行后面的操作。它和CountDownLatch有些相似的地方，都是通过计数器来实现。当某个线程调用
了await方法之后，该线程就进入等待状态，而且计数器执行+1操作。当计数器的值达到我们设置的初始值之后
因为调用这个await方法进入等待状态的线程会被唤醒继续执行他们后续的操作。由于CyclicBarrier在释放
等待线程后可以重用，所以又称它为是循环屏障，可以一致循环使用。

## 使用场景
CyclicBarrier跟CountDownLatch很相似，CyclicBarrier可以用于多线程计算数据，最后合并计算结果的
应用场景，比如，用一个excel保存了所有的银行流水，excel的每一页保存了一个账户一年的每一笔银行流水，
现在需要统计日均银行流水，就可以先用多线程处理每个页里面的银行流水都执行完成之后得到每个页的日均
银行流水，之后通过CyclicBarrier action利用这些线程执行结果，计算出整个excel的日均银行流水。


## CyclicBarrier与CountDownLatch的区别
* CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset方法重置，循环使用
* CountDownLatch主要是实现一个或N个线程需要等待其他线程完成某项操作之后才能继续往下执行，它描述
的是一个或N个线程等待其他线程的关系；CyclicBarrier主要是实现了多个线程之间相互等待，直到所有线程
都满足了条件之后才能继续执行手续的操作，它描述的是各个线程内部相互等待的关系。
  - 比如启动了多个线程，每个线程如果准备好了之后就调用await方法等待，比如之前设置的屏障是5个线程，
  如果5个线程都调用了await方法，那么相当于它们都准备好了，接下来才允许它们一起往下执行
  - CyclicBarrier他能处理更复杂的业务场景。比如说，如果计算错误了可以重置计数器，并让线程们重新执行
  一次，CyclicBarrier还提供了其他有用的方法，比如说getNumberWaiting可以获取CyclicBarrier阻塞
  的线程数量，还可以通过isBroken用来知道阻塞的线程是否已经被中断了

# ReentrantLock与锁

java主要分两类锁，一类是synchronized关键字修饰的锁，一类是J.U.C提供的锁。J.U.C里核心的锁就是
ReentrantLock。ReentrantLock核心方法是lock与unlock。其他提供的很多方法是其灵活性的原因

## ReentrantLock与synchronized区别
* 可重入性 : ReentrantLock是可重入锁，实际上synchronized关键字修饰的锁也是可重入的。两种区别
不大，都是同一个线程进入一次锁的计数器就自增一，所以要等到锁的计数器下降为零时才能释放锁。
* 锁的实现 : synchronized关键字是依赖于JVM实现的，而ReentrantLock是JDK实现的。类似于操作系统
来控制实现和用户自己代码实现的区别。ReentrantLock可以通过阅读源码来知道具体实现，synchronized
则很难。
* 性能的区别 : 在synchronized关键字优化以前synchronized的性能比ReentrantLock差很多，但是自从
它引入来偏向锁轻量级锁（也就是自旋锁）后它们两者的性能就差不多了。在两种方法都可用的情况下，官方更
建议使用synchronized，因为它的写法更容易。其实synchronized优化感觉像借鉴了ReentrantLock中的
CAS计数。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。
* 功能区别
  - 便利性 : 很明显synchronized的使用比较方便简洁，并且它是由编译器去保证锁的加锁和释放的。而
  ReentrantLock需要我们手动声明来加锁和释放锁。为了避免忘记手动释放锁造成死锁，所以最好是在finally
  中声明释放锁。
  - 锁的细粒度与灵活度 : ReentrantLock优于synchronized
* ReentrantLock独有的功能
  - 可指定是公平锁还是非公平锁，synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得
  锁
  - 提供了一个Condition类，可以分组唤醒需要唤醒的线程，而不是像synchronized要么随机唤醒一个
  线程，要么唤醒全部线程。
  - 提供能够中断等待锁的线程的机制，通过lock.lockInterruptibly()实现这个机制。ReentrantLock
  实现是一种自旋锁，通过循环调用CAS操作来实现加锁，它的性能比较好也是因为避免了使线程进入内核态
  阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去理解和分析所设计的关键钥匙。
## 使用场景
如果需要实现ReentrantLock三个独有功能的时候必须使用ReentrantLock，其它情况下可以根据性能或者
当时的业务场景来选择使用ReentrantLock还是synchronized，通过介绍我们知道ReentrantLock相对
synchronized来说synchronized能做的事情ReentrantLock都能做，而ReentrantLock能做的synchronized
却有很多做不了。性能方面ReentrantLock也不必synchronized差。那么需不需要抛弃synchronized呢？
java.util.concurrent.locks包中的锁定类是用于高级用户和高级情况的工具，一般来说除非你对lock的
某个高级特性有明确的需要，或者有明确的证据，不仅仅是怀疑，表明在特定的情况下同步已经成为可伸缩性的
瓶颈的时候，否则建议还是继续使用synchronized，即使对于这些高级锁定的类来说synchronized仍然有
一些优势，比如在使用synchronized的时候不可能忘记释放锁，在退出synchronized块的时候JVM会为你做
这些事情，你会很容易忘记用finally去释放锁，这对程序非常有害。程序即使能够通过测试，但会在实际工作
中出现死锁，那时候会很难指出原因，这也是不是很建议初级开发人员使用lock的好理由。另外的一个原因是
因为JVM用synchronized管理锁定请求和释放时，JVM在生成线程转储时能够包括锁定信息，这对调试非常有
价值，因为他们能标示死锁或者其他异常行为的来源。而lock类其实只是普通的类，JVM不知道具体哪一个线程
拥有lock对象，而且几乎每个开发人员都熟悉synchronized，它可以在JVM的所有版本中工作，在JDK5.0成为
标准之前，使用lock类就意味着要利用特性而不是每个JVM都有的，而且不是每个开发人员都熟悉的。在实际项目
中大家遇到的需要加锁的情景其实大部分都可以使用synchronized来解决。

## 其他方法
* lockInterruptibly() : 如果当前线程没有被中断那么就获取锁定，如果已经被中断了，就抛出异常。
* isLock() : 查询此锁定是否由任意线程保持
* isHeldByCurrentThread() : 查询当前线程是否保持锁定状态
* isFair() : 是否公平锁
* hasQueuedThread : 查询指定线程是否在等待获取此锁定
* hasQueuedThreads : 查询是否有线程正在等待获取此锁定
* getHoldCount() : 查询当前线程保持锁定的个数，也就是调用lock方法的个数

## 公平锁与非公平锁的区别

请参考 [一张图读懂非公平锁与公平锁](https://www.jianshu.com/p/f584799f1c77)

1、若在释放锁的时候总是没有新的兔子来打扰，则非公平锁等于公平锁；

2、若释放锁的时候，正好一个兔子来喝水，而此时位于队列头的兔子还没有被唤醒（因为线程上下文切换是需要不少开销的），此时后来的兔子则优先获得锁，成功打破公平，成为非公平锁；

# ReentrantReadWriteLock
它里面有两个锁，一个读锁，一个写锁。
在没有任何读写锁的时候才可以取得写入锁。它可以用于实现了悲观读取，即如果我们执行中
进行读取时经常有另外一个线程需要写入的需求。为了保证同步ReentrantReadWriteLock
的读取锁定就可以派上用场。然而如果读取执行情况很多、写入很少的情况下使用
ReentrantReadWriteLock可能会使写入线程遭遇饥饿，也就是写入线程迟迟无法竞争到锁定
而一致处于等待状态。

# StampedLock
Java 8 引入了一个新的读写锁叫StampedLock. StampedLock控制锁有三种模式，独占写、悲观读、乐观读。
StampedLock的状态是由版本和模式两个部分组成。锁的获取方法返回的是一个数字作为票据。它用相应的
锁状态来表示并控制相关的访问。数字0表示没有写锁被授权访问。在读锁上分为悲观锁和乐观锁。

所谓乐观读其实也就是如果读的操作很多，写的操作很少的情况下可以乐观的认为写入与读取同时发生的几率
很少，因此不悲观的使用会完全读取锁定的悲观锁。不仅这个锁更快，而且它提供强大的乐观锁API，
这意味着你能以一个较低的代价获得一个读锁, 在这段时间希望没有写操作发生，当这段时间完成后，
你可以查询一下锁，看是否在刚才这段时间是否有写操作发生,然后你可以决定是否需要再试一次或升
级锁或放弃。

# Condition
Condition是多线程间协调通讯的工具类，使得某个或者某个线程一起等待某个条件，只有当该条件具备这些
等待的线程才会被唤醒。这里的具备条件就是我们得到的信号和重新获取锁。发送信号包含signalALl还是signal的
方法。这些等待的线程

# 互斥锁（互斥量）的开销
互斥锁的开销主要在内核态与用户态的切换。

申请锁时，从用户态进入内核态，申请到后从内核态返回用户态（两次切换）；
没有申请到时阻塞睡眠在内核态。使用完资源后释放锁，从用户态进入内核态，唤醒阻塞等待锁的进程，返回用户态（又两次切换）；
被唤醒进程在内核态申请到锁，返回用户态（可能其他申请锁的进程又要阻塞）。所以，使用一次锁，包括申请，持有到释放，当前进程要进行四次用户态与内核态的切换。
同时，其他竞争锁的进程在这个过程中也要进行一次切换。

进程上下文切换的直接消耗包括CPU寄存器保存和加载，需要调度时有内核调度代码的执行。

# 总结
* 当只有少量竞争者的时候synchronized是一个很好的通用的锁实现。
* 竞争者不少，但是它线程增长的趋势是能够预估的，这时候ReentrantLock是一个很好的通用的锁
实现。
> 在使用锁的时候一定不是看哪个锁高级就用哪一个，适合自己的使用场景的才是最关键的。这里尤其
需要注意的是synchronized不会引发死锁，JVM会自动解锁。而其他的锁如果使用不当是有可能造成
死锁的，因为有可能在某些情况下没有执行unlock操作。

# FutureTask
FutureTask不是AQS的子类，但是这个类对线程结果的处理值得在项目中使用。
## 创建一个线程的两种方式
* 直接继承Thread
* 实现Runnable接口
> 它们的共同缺陷是在执行完任务完成之后无法获取任务执行结果。
从java1.5开始就提供了Callable和Future，通过他们可以在任务执行完毕之后得到任务执行的结果。

## Callable与Runnable接口对比
Runnable代码非常简单，只有一个方法就是run。
Callable代码也非常简单，不同的是它是范型的接口。它里面有一个call函数，call函数的返回类型
就是我们创建callable传进入类型。callable与Runnable的功能大致相似Callable功能更强大一些，
主要是线程执行之后可以有返回值，并且可以抛出异常。

## Future接口
在Java中，如果需要设定代码执行的最长时间，即超时，可以用Java线程池ExecutorService类配合
Future接口来实现。 Future接口是Java标准API的一部分，在java.util.concurrent包中。
Future接口是Java线程Future模式的实现，可以来进行异步计算。

### Future模式
可以这样来描述：我有一个任务，提交给了Future，Future替我完成这个任务。期间我自己可以去做
任何想做的事情。一段时间之后，我就便可以从Future那儿取出结果。就相当于下了一张订货单，
一段时间后可以拿着提订单来提货，这期间可以干别的任何事情。其中Future 接口就是订货单，
真正处理订单的是Executor类，它根据Future接口的要求来生产产品。

Future接口提供方法来检测任务是否被执行完，等待任务执行完获得结果，也可以设置任务执行的超时时间。这个设置超时的方法就是实现Java程序执行超时的关键。

Future接口是一个泛型接口，严格的格式应该是Future<V>，其中V代表了Future执行的任务返回值的类型。 Future接口的方法介绍如下：
```java
interface Future {
    boolean cancel (boolean mayInterruptIfRunning); //取消任务的执行。参数指定是否立即中断任务执行，或者等等任务结束
    boolean isCancelled(); //任务是否已经取消，任务正常完成前将其取消，则返回 true
    boolean isDone();// 任务是否已经完成。需要注意的是如果任务正常终止、异常或取消，都将返回true
    V get() throws InterruptedException,ExecutionException; //等待任务执行结束，然后获得V类型的结果。InterruptedException 线程被中断异常， ExecutionException任务执行异常，如果任务被取消，还会抛出CancellationException
    V get (long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;// 同上面的get功能一样，多了设置超时时间。参数timeout指定超时时间，uint指定时间的单位，在枚举类TimeUnit中有相关的定义。如果计算超时，将抛出TimeoutException
}
```

## FutureTask
FutureTask的父类是RunnableFuture，而RunnableFuture继承了Runnable和Future着两个接口。
由此可知，FutureTask最终也是执行Callable类型的任务，如果构造函数参数是Runnable的话它会
转换成Callable类型。FutureTask实现了两个接口，所以它既可以作为Runnable被线程执行，又可以
作为Future作为Callable的返回值。
### 那么这个组合的使用有什么好处呢？
假设有一个很费事的逻辑需要计算并且返回这个值，同时这个值又不是马上需要，那么就可以使用这种组合。
用另外一个线程去计算返回值，而当前线程呢在使用这个返回值之前可以做其他的操作，等到需要这个返回值
时再通过Future得到。

# Fork/Join框架
![image-20200130215722130](https://tva1.sinaimg.cn/large/006tNbRwgy1gbexmbx16rj30bq0a8n02.jpg)

类似于map reduce。
工作原理是使用了工作窃取算法，某个线程从其他队列窃取任务来执行。
## 使用工作窃取算法的原因
加入需要做一个比较大的任务，我们可以把这个任务分割成若干个互不依赖的子任务，为了节省线程间的
竞争，由于把这些子任务分别放到不同的队列里，为每个队列创建一个单独的线程来执行队列里的任务。
线程和队列一一对应，有的线程会先把自己队列里的任务执行完，而其他线程对应的队列还有任务等待
处理，于是空闲的线程会去其他线程里的队列窃取一个任务来执行，而在这时他们会访问同一个队列，所以
为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用的是双端队列，被窃取任务的线程永远从
双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部窃取任务执行。这个优点就是充分
利用线程进行并行计算，并减少了线程之间的竞争。缺点是在某些情况下，还是存在竞争，比如双端队列
只有一个任务时，同时这样还消耗了更多系统资源，比如创建了多个线程，有多个双端队列。对于Fork/Join
框架而言，当一个任务正在等待它使用Join操作创建的子任务结束时，执行这个任务的工作线程查找其他
未被执行的任务并开始它的执行，通过这种方式线程充分利用他们的运行时间来提高应用程序的性能。

## 局限性
* 任务只能使用Fork和Join操作来作为同步机制，如果使用了其他同步的机制，那么他们在进行
同步操作时工作线程就不能执行其他任务了，比如在Fork/Join框架中你使任务进行了睡眠，那么
在这个睡眠期间内正在执行这个任务的工作线程就不能执行其他任务了。
* 任务不应该去执行IO操作，如读写数据文件，
* 任务不能抛出检查异常

# BlockingQueue
BlockingQueue不光实现了一个完整队列所具有的基本功能，同时在多线程环境下它还自动管理了多线程
间的自动等待、唤醒功能，从而使得我们开发人员可以忽略这些细节，关注更高级的功能。
* ArrayBlockingQueue
有界阻塞队列，内部实现是一个数组。有界的意思是它的容量是有限的，我们必须在其初始化的时候
指定它的容量大小，这个大小一般指定了就不能再变了。ArrayBlockingQueue是以先进先出的方式
处理数据，最先插入的数据在尾部，最新移除的对象是头部
* DelayQueue
阻塞的是内部元素，DelayQueue内部的元素必须实现一个接口J.U.C中的Delayed接口，这个Delayed
继承了Comparable接口，这是因为DelayQueue中的元素需要进行排序，一般情况下我们都是按照元素
过期时间的优先级进行排序。
  - 应用场景
    * 定时关闭连接
    * 缓存对象
    * 超时处理
  - 内部实现 : 基于PriorityQueue和ReentrantLock
* LinkedBlockingQueue
LinkedBlockingQueue组件队列大小配置是可选的，如果初始化时指定了一个大小，那么它就是有边界
的，如果没有就是无边界的。所谓无边界就是使用了默认的最大的整型值，它的内部实现是一个链表。
除了内部实现结构不一样其他大部分和ArrayBlockingQueue一样。LinkedBlockingQueue也是以先进
先出的方式储存数据，最新插入的数据在尾部，最新移除的对象在头部。
* PriorityBlockingQueue
PriorityBlockingQueue是一个带优先级的阻塞队列。PriorityBlockingQueue是一个没有边界的
队列，但是它是有排序规则的，需要注意的是这个PriorityBlockingQueue是允许插入null的。如果
使用PriorityBlockingQueue插入的对象必须实现comparable接口。队列的优先级排序规则就是按照
对comparable接口的实现来定义的。我们可以从PriorityBlockingQueue中获得一个迭代器，但是
这个迭代器并不保证按照我们优先级的顺序进行迭代。
* SynchronousQueue
SynchronousQueue内部仅允许一个元素，当一个线程插入一个元素后就会被阻塞，除非这个元素被另一个
线程消费，因此我们称它为同步队列，它是一个无界非缓存的队列，它不存储元素，放入元素只有等待取走
元素之后才能放入。