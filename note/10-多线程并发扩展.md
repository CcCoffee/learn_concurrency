# 死锁
## 产生死锁的原因：
* 因为系统资源不足。
* 进程运行推进的顺序不合适。
* 资源分配不当等。

如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则
就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。
## 必要条件
* 互斥条件 : 线程对所分配的资源进行排他性的使用，即在一段时间内某资源只有一个线程占用，如果此时
还有其他线程要占用资源那么只能等待，直到占有资源的线程释放锁
* 请求和保持条件 : 指线程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他线程所
占用，此时请求线程阻塞，但又对自己的或其他资源保持不放
* 不剥夺条件 : 线程已获得资源在未使用完之前不被被剥夺锁，只能在使用完时自己释放
* 环路等待条件 : 若干线程之间形成一种头尾相接的循环等待资源关系。

## 避免死锁的3种办法
### 加锁顺序
线程一定要按照一定的顺序去加锁，如果线程1先对lock1加锁，再对lock2加锁。线程2先对lock2加锁，再
对lock1加锁就会造成死锁。需要代码来保证同时对lock1加锁或者同时对lock2加锁才可以。
### 加锁实现
系统在尝试获取锁的时候可以加上一个时限，超过这个时间就放弃该锁的请求，并释放自己占有的锁。在线程1
占用lock1时可以不使用synchronized关键字而使用ReentrantLock，它支持加锁给定超时时间。lock2也
换成带时限的获取锁方法。假设线程1和线程2出现相互等待的时候也会因为超时放弃锁
### 死锁检测
死锁检测实际上难以实现，通常不会有人写代码去做死锁检测。它是一种比较好的死锁预防的机制，它主要是
针对那些不可能实现按序加锁并且锁超时也不可行的场景，每当一个线程获得一个锁会在线程或锁相关的数据
结构（map、graph等等）中记下来，除此之外每当有线程请求锁也需要记录下数据结构中

当一个线程请求锁失败时，这个线程可以遍历锁的关系图看看是否有死锁发生。例如，线程A请求锁7，但是
锁7这个时候被线程B持有，这时线程A就可以检查一下线程B是否已经请求了线程A当前所持有的锁。如果线程
B确实有这样的请求，那么就是发生了死锁（线程A拥有锁1，请求锁7；线程B拥有锁7，请求锁1）。

当然，死锁一般要比两个线程互相持有对方的锁这种情况要复杂的多。线程A等待线程B，线程B等待线程C，线
程C等待线程D，线程D又在等待线程A。线程A为了检测死锁，它需要递进地检测所有被B请求的锁。从线程B所请
求的锁开始，线程A找到了线程C，然后又找到了线程D，发现线程D请求的锁被线程A自己持有着。这是它就知道
发生了死锁。

下面是一幅关于四个线程（A,B,C和D）之间锁占有和请求的关系图。像这样的数据结构就可以被用来检测死锁。

![image-20200131141545000](https://tva1.sinaimg.cn/large/006tNbRwgy1gbfpwac6rij306909v74j.jpg)

#### 那么当检测出死锁时，这些线程该做些什么呢？

一个可行的做法是释放所有锁，回退，并且等待一段随机的时间后重试。这个和简单的加锁超时类似，不一样的
是只有死锁已经发生了才回退，而不会是因为加锁的请求超时了。虽然有回退和等待，但是如果有大量的线程竞
争同一批锁，它们还是会重复地死锁（编者注：原因同超时类似，不能从根本上减轻竞争）。

一个更好的方案是给这些线程设置优先级，让一个（或几个）线程回退，剩下的线程就像没发生死锁一样继续保
持着它们需要的锁。如果赋予这些线程的优先级是固定不变的，同一批线程总是会拥有更高的优先级。为避免这
个问题，可以在死锁发生的时候设置随机的优先级

# 多线程并发最佳实践
## 使用本地变量
尽量使用本地变量，而不是创建一个类或实例的变量。

## 使用不可变类
String、Integer等。不可变类可以降低代码中需要的同步数量。

## 最小化锁的作用域范围：S=1/(1-a+a/n)
a：并行计算部分所占比例

n：并行处理结点个数

S：加速比

当1-a等于0时，没有串行只有并行，最大加速比 S=n

当a=0时，只有串行没有并行，最小加速比 S = 1

当n→∞时，极限加速比 s→ 1/（1-a）

例如，若串行代码占整个代码的25%，则并行处理的总体性能不可能超过4。

该公式称为："阿姆达尔定律"或"安达尔定理"。

## 使用线程池的Executor，而不是直接new  Thread 执行
创建一个线程的代价是昂贵的，如果要创建一个可伸缩的Java应用，那么你需要使用线程池。

## 宁可使用同步也不要使用线程的wait和notify
从Java1.5以后，增加了许多同步工具，如：CountDownLatch、CyclicBarrier、Semaphore等，应该优
先使用这些同步工具。

## 使用BlockingQueue实现生产-消费模式
阻塞队列不仅可以处理单个生产、单个消费，也可以处理多个生产和消费。

## 使用并发集合而不是加了锁的同步集合
Java提供了下面几种并发集合框架：

ConcurrentHashMap、CopyOnWriteArrayList、CopyOnWriteArraySet、ConcurrentLinkedQueue 、
ConcurrentLinkedDeque等（相关介绍请见Java 并发编程（九）并发集合框架）

## 使用Semaphore创建有界的访问
为了建立稳定可靠的系统，对于数据库、文件系统和socket等资源必须要做有机的访问，Semaphore可以限制
这些资源开销的选择，Semaphore可以以最低的代价阻塞线程等待，可以通过Semaphore来控制同时访问指定
资源的线程数。

## 宁可使用同步代码块，也不使用同步的方法
主要针对synchronized关键字。使用synchronized关键字同步代码块只会锁定一个对象，而不会将整个方法
锁定。如果更改共同的变量或类的字段，首先应该选择的是原子型变量，然后使用volatile。如果需要互斥锁，
可以考虑使用ReentrantLock。

## 避免使用静态变量
静态变量在并发执行环境下会制造很多问题，如果必须使用静态变量，那么优先是它成为final变量，如果用来
保存集合collection，那么可以考虑使用只读集合，否则一定要做特别多的同步处理和并发处理操作。

# Spring与线程安全
Spring作为一个IOC/DI容器，帮助我们管理了许许多多的“bean”。但其实，Spring并没有保证这些对象的线
程安全，需要由开发者自己编写解决线程安全问题的代码。

Spring对每个bean提供了一个scope属性来表示该bean的作用域。它是bean的生命周期。例如，一个scope为
singleton的bean，在第一次被注入时，会创建为一个单例对象，该对象会一直被复用到应用结束。

* singleton：默认的scope，每个scope为singleton的bean都会被定义为一个单例对象，该对象的生命周期是
与Spring IOC容器一致的（但在第一次被注入时才会创建）。

* prototype：bean被定义为在每次注入时都会创建一个新的对象。

* request：bean被定义为在每个HTTP请求中创建一个单例对象，也就是说在单个请求中都会复用这一个单例对象。

* session：bean被定义为在一个session的生命周期内创建一个单例对象。

* application：bean被定义为在ServletContext的生命周期中复用一个单例对象。

* websocket：bean被定义为在websocket的生命周期中复用一个单例对象。

我们交由Spring管理的大多数对象其实都是一些无状态的对象，这种不会因为多线程而导致状态被破坏的对象很
适合Spring的默认scope，每个单例的无状态对象都是线程安全的（也可以说只要是无状态的对象，不管单例多
例都是线程安全的，不过单例毕竟节省了不断创建对象与GC的开销）。
> 我们平时使用单例的Spring bean没有什么性能问题，很关键一点是我们只是简单的使用，不涉及到修改bean
的内部属性及状态相关的量，相当于是不会出现多个线程修改相同的变量的场景

无状态的对象即是自身没有状态的对象，自然也就不会因为多个线程的交替调度而破坏自身状态导致线程安全问题。
无状态对象包括我们经常使用的DO、DTO、VO这些只作为数据的实体模型的贫血对象，还有Service、DAO和
Controller，这些对象并没有自己的状态，它们只是用来执行某些操作的。例如，每个DAO提供的函数都只是对数
据库的CRUD，而且每个数据库Connection都作为函数的局部变量（局部变量是在用户栈中的，而且用户栈本身就
是线程私有的内存区域，所以不存在线程安全问题），用完即关（或交还给连接池）。

有人可能会认为，我使用request作用域不就可以避免每个请求之间的安全问题了吗？这是完全错误的，因为
Controller默认是单例的，一个HTTP请求是会被多个线程执行的，这就又回到了线程的安全问题。当然，你也可
以把Controller的scope改成prototype，实际上Struts2就是这么做的，但有一点要注意，Spring MVC对请求
的拦截粒度是基于每个方法的，而Struts2是基于每个类的，所以把Controller设为多例将会频繁的创建与回收
对象，严重影响到了性能。

通过阅读上文其实已经说的很清楚了，**Spring根本就没有对bean的多线程安全问题做出任何保证与措施。**
对于每个bean的线程安全问题，根本原因是每个bean自身的设计。**不要在bean中声明任何有状态的实例变量
或类变量**，如果必须如此，那么就使用ThreadLocal把变量变为线程私有的，如果bean的实例变量或类变量
需要在多个线程之间共享，那么就只能使用synchronized、lock、CAS等这些实现线程同步的方法了。

# HashMap与ConcurrentHashMap

![image-20200131152839637](https://tva1.sinaimg.cn/large/006tNbRwgy1gbfs063x1tj30by09ojsq.jpg)

## HashMap参数

有两个参数影响他的性能

* 初始容量（默认为16）: 容量是Hash表中桶的数量，初始容量只是Hash表在创建时的容量
* 加载因子（默认是0.75）: 加载因子是Hash表在容量增长之前可以达到多满的一个尺度。当hash表中的条目
数量超过了加载因子与当前容量的乘积，比如默认为16*0.75=12的时候，将会调用resize方法进行扩容，然后
将容量进行翻倍。

## HashMap寻址方式

对一个我们需要插入的数据或者我们要读取的数据，首先hashMap会将它的key按照一定的计算规则计算出的
hash值并对我们的数组长度进行取模，结果作为插入数组织位置的index.

在计算机中，取模的代价远远高于位移的代价，因此hashMap要求数组的长度一定是2的n次方；此时它将key
的hash值对2的（n-1）次方进行与运算，它的结果与我们的取模操作是相同的，hashMap在初始化的时候，
并不要求用户一定传入一个2的n次方的整数，而是根据传入的值，计算出一个满足2的n次方的容量(tableSizeFor方法)。

## hashMap不安全的原因
在hash进行resize的时候，容易出现死循环。以及在使用迭代器的时候 容易发生fast-fail
* fast-fail : fail-fast 机制是java集合(Collection)中的一种错误机制。当多个线程对同一个集合的
内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，
若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException
异常，产生fail-fast事件。
## 单线程下的rehash
<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gbfrqpkigxj30jw0cdmyw.jpg" alt="12" style="zoom:67%;" />
* 扩容之前容量是2，加载因子是1。这是放入2个元素，5和9。放入第三个元素时就需要扩容
* 扩容第一步是新创建一个数组，他的长度是原来长度的2倍。接下来需要把原来数组中的元素rehash到数组
里面去。原本的5元素假设它的hash值还是5，对数组取模(5%4=1)之后是1。相当于放在数组索引为1的位置的
链表的首位
* 之后第二项是9，9%4=1，相当于是在数组下标为1的位置的链表上插入9进来。变成链表上是9->5。
* 第三项11哈希之后11%4=3，相当于是在数组下标为3的位置的链表上插入11。

## 多线程下的rehash
* 假设我们有两个线程。我用红色和浅蓝色标注了一下。我们再回头看一下我们的 transfer代码中的这个细节：
    ```java
    class HashMap {
        public void xxx(){
            do {
                Entry<K,V> next = e.next; // <--假设线程一执行到这里就被调度挂起了
                int i = indexFor(e.hash, newCapacity);
                e.next = newTable[i];
                newTable[i] = e;
                e = next;
            } while (e != null);
        }
    }
    ```
    ![](https://images.cnblogs.com/cnblogs_com/andy-zhou/817145/o_HashMap002.jpg)
    注意：因为Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后
的链表。我们可以看到链表的顺序被反转后。
* 线程一被调度回来执行。
  - 先是执行 newTable[i] = e。
  - 然后是e = next，导致了e指向了key(7)。
  - 而下一次循环的next = e.next导致了next指向了key(3)。
    ![](https://images.cnblogs.com/cnblogs_com/andy-zhou/817145/o_HashMap003.jpg)
* 一切安好，线程一接着工作。把key(7)摘下来，放到newTable[i]的第一个，然后把e和next往下移。
  ![](https://images.cnblogs.com/cnblogs_com/andy-zhou/817145/o_HashMap004.jpg)
* 环形链接出现。e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的
key(7).next已经指向了key(3)， 环形链表就这样出现了。
![](https://images.cnblogs.com/cnblogs_com/andy-zhou/817145/o_HashMap005.jpg)
于是，当我们的线程一调用到HashTable.get(11)时，悲剧就出现了——Infinite Loop。
### 三种解决方案
* Hashtable替换HashMap
* Collections.synchronizedMap将HashMap包装起来
* ConcurrentHashMap替换HashMap
## ConcurrentHashMap
concurrentHashMap与HashMap不同的是，在jdk7中的底层最外层不是一个一个大的数组，而是一个Segment数组，
每个Segment数组包含一个跟hashMap差不多的链表。Segment继承自ReentrantLock，所以Segment能够
很方便的对数组进行上锁。jdk8放弃了使用Segment的优化，而是使用了红黑树代替了链表，使得时间复杂度从
O(n)变成了O(log(n))。
